This code is a MATLAB implementation of *chordal conversion* that uses
[MOSEK](https://www.mosek.com/) to solve a standard-form semidefinite
program (SDP) over a single *n*â€…Ã—â€…*n* matrix variable and subject to *m*
linear constraints:

min<sub>*X*â€„â‰½â€„0</sub>{âŸ¨*C*,*X*âŸ©:lb<sub>*i*</sub>â‰¤âŸ¨*A*<sub>*i*</sub>,*X*âŸ©â‰¤ub<sub>*i*</sub> for all *i*âˆˆ{1,2,â€¦,*m*}},

where *X*â€„â‰½â€„0 indicates that the matrix variable *X* should be symmetric
positive semidefinite.

The problem data are the objective matrix *C*â€„âˆˆâ€„ğ•Š<sup>*n*</sup>, the
list of *m* constraint matrices
*A*<sub>1</sub>,â€†*A*<sub>2</sub>,â€†â€¦,â€†*A*<sub>*m*</sub>â€„âˆˆâ€„ğ•Š<sup>*n*</sup>
and associated lower-bounds
lb<sub>1</sub>,â€†lb<sub>2</sub>,â€†â€¦,â€†lb<sub>*m*</sub>â€„âˆˆâ€„â„â€…âˆªâ€…{â€…âˆ’â€…âˆ} and
upper-bounds
ub<sub>1</sub>,â€†ub<sub>2</sub>,â€†â€¦,â€†ub<sub>*m*</sub>â€„âˆˆâ€„â„â€…âˆªâ€…{â€…+â€…âˆ}, where
ğ•Š<sup>*n*</sup> is the set of *n*â€…Ã—â€…*n* real symmetric matrices. In this
case, the matrix inner product is explicitly written
âŸ¨*C*,â€†*X*âŸ©â€„=â€„trace(*C*<sup>*T*</sup>*X*).

**Main feature.** Under suitable *small treewidth* assumptions (see
below), the code will reduce MOSEKâ€™s per-iteration cost to *O*(*m*+*n*)
time. Given that MOSEK usually converges to *Ïµ*â€„=â€„10<sup>âˆ’8</sup> in
less than ten iterations, the total cost of solving the SDP is also
essentially *O*(*m*+*n*) time.

To give some benchmark numbers, the code is able to solve a Lovasz Theta
problem with *n*â€„=â€„10<sup>6</sup> and *m*â€„=â€„1.5â€…Ã—â€…10<sup>6</sup> in 30
minutes, and an AC optimal power flow relaxation with
*n*â€„=â€„8.2â€…Ã—â€…10<sup>4</sup> and *m*â€„â‰ˆâ€„2.5â€…Ã—â€…10<sup>5</sup> in less than 4
hours, on a modest workstation with a Xeon 3.3 GHz quad-core CPU and 32
GB of RAM.

**Complex data.** The code also natively supports complex-valued data
*C*,â€†*A*<sub>1</sub>,â€†*A*<sub>2</sub>,â€†â€¦,â€†*A*<sub>*m*</sub>â€„âˆˆâ€„â„<sup>*n*</sup>,
where â„<sup>*n*</sup> is the set of *n*â€…Ã—â€…*n* complex Hermitian
matrices. The matrix inner product is now
âŸ¨*C*,â€†*X*âŸ©â€„=â€„Re{trace(*C*<sup>*H*</sup>*X*)}, in which the superscript
*H* indicates the conjugate transpose. (The bounds lb<sub>*i*</sub> and
ub<sub>*i*</sub> must still be real-valued.)

**Citation.** If you find this code helpful or use it in your projects,
please cite:

# Installation and usage notes

This code works with the commerical [MOSEK](https://www.mosek.com/)
solver ([a free academic license is available
here](https://www.mosek.com/products/academic-licenses/)). The base
command `mosekopt` must be added to the search path.

Once unzipped, the base calling sequence is the following.

    [U,v,info] = solveChordalConv(c,At,lb,ub)

The input is provided in SeDuMi format:

-   `c` is an *n*<sup>2</sup>â€…Ã—â€…1 sparse vector representing the
    column-wise vectorization vec(*C*). In MATLAB, this kind of
    vectorization can be implemented by calling `c=C(:). `

-   `At` is an *n*<sup>2</sup>â€…Ã—â€…*m* sparse matrix, whose *j*-th column
    represents the column-wise vectorization vec(*A*<sub>*i*</sub>) of
    the *i*-th constraint matrix. The *n*â€…Ã—â€…*n* matrices
    *C*,â€†*A*<sub>1</sub>,â€†â€¦,â€†*A*<sub>*m*</sub> can be either real
    symmetric or complex Hermitian.

-   `lb` and `ub` are dense *m*â€…Ã—â€…1 vectors, whose *i*-th elements
    represent lb<sub>*i*</sub>â€„âˆˆâ€„â„â€…âˆªâ€…{â€…âˆ’â€…âˆ} and
    ub<sub>*i*</sub>â€„âˆˆâ€„â„â€…âˆªâ€…{â€…+â€…âˆ} respectively. All elements must
    satisfy lb<sub>*i*</sub>â€„â‰¤â€„ub<sub>*i*</sub>.

The output is given as follows

-   `U` is the *n*â€…Ã—â€…*r* dense factor matrix *U*, which recovers the SDP
    solution *X* via the Hermitian outer product `X=UUâ€™`. The matrix `U`
    may be real or complex. **Warning:** Explicitly forming *X* will
    ruin the *O*(*m*+*n*) time complexity of the algorithm. In almost
    all cases, operations with *X* can be directly replaced by
    operations with *U*.

-   `v` is an *m*â€…Ã—â€…2 dense matrix, containing the dual Lagrange
    multipliers. 

-   `info` is a struct containing various timing information.

# The small treewidth assumption

A necessary condition for the code to be fast is that the aggregate
sparsity graph *G*â€„=â€„(*V*,*E*) defined below should have a *small
treewidth*:

*V*â€„=â€„{1,â€†2,â€†â€¦,â€†*n*},â€Šâ€*E*â€„=â€„spar(*C*)â€…âˆªâ€…spar(*A*<sub>1</sub>)â€…âˆªâ€…â‹¯â€…âˆªâ€…spar(*A*<sub>*m*</sub>),

where
spar(*C*)â€„â‰¡â€„{(*i*,*j*)â€„:â€„*C*\[*i*,*j*\]â€„â‰ â€„0 for *i*â€„\>â€„*j*}.
In other words, if *G* does *not* have a small treewidth, then the code
is guaranteed *not* to be fast. (But the code may be slow even if *G*
does have a small treewidth.)

In MATLAB, the adjacency matrix for the graph *G* is easily computed.

    Adj = reshape(any([c,At],2),n,n); 

We can compute an upper-bound on tw(*G*) by performing symbolic Cholesky
factorization on the adjacency matrix.

    p = amd(Adj); % fill-reducing permutation
    twub = max(symbfact(Adj(p,p))-1; % symbolic Cholesky factor

Conversely, if *G* has a small treewidth, then the code may be fast or
it may be slow. For example, if we set
*C*,â€†*A*<sub>1</sub>,â€†â€¦,â€†*A*<sub>*m*</sub> to all be diagonal matrices
with dense diagonals, then the code will be slow.

A sufficient condition for the code to be fast is that the *extended*
aggregate sparsity graph *G*<sup>ext</sup>â€„=â€„(*V*,*E*<sup>ext</sup>)
defined below also needs to have a small treewidth:

*V*â€„=â€„{1,â€†2,â€†â€¦,â€†*n*},â€Šâ€*E*<sup>ext</sup>â€„=â€„spar(*C*)â€…âˆªâ€…clique(*A*<sub>1</sub>)â€…âˆªâ€…â‹¯â€…âˆªâ€…clique(*A*<sub>*m*</sub>)

where
clique(*A*)â€„=â€„{(*i*,*j*)â€„:â€„*A*\[*i*,*k*\]â€„â‰ â€„0 or *A*\[*k*,*j*\]â€„â‰ â€„0 for some *k*}.
In other words, if *G*<sup>ext</sup> has a small treewidth, then the
code is guaranteed to be fast. (But the code may be fast even if
*G*<sup>ext</sup> does not have a small treewidth.)

It turns out to be surprisingly difficult to efficiently compute the
adjancecy matrix of *G*<sup>ext</sup> once *n* and *m* become large. We
provide an efficient implementation below.

    [~,AdjExt] = sparseGraph(c,At);

We can then proceed to upper-bound tw(*G*<sup>ext</sup>) using the same
idea as above:

    p = amd(AdjExt); % fill-reducing permutation
    twub = max(symbfact(AdjExt(p,p))-1; % symbolic Cholesky factor

The rigorous guarantee is useful for applications where worst-case
runtime guarantee is required.

# Options structure

The code accepts an options structure for some advanced tuning.

    opt = struct('verbose',0);
    [U,v,info] = solveChordalConv(c,At,lb,ub,opt)

The fields of the options structure `opt` are:

-   â€™verboseâ€™ is set to 0 to turn off printouts.

-   â€™norecoverâ€™ is set to TRUE if we only solve the SDP without
    recovering the minimizer *X*.

-   â€™permâ€™ allows a custom elimination ordering to be provided in
    computing the tree decomposition.

-   â€™naturalâ€™ forces MOSEK to use the natural elimination ordering,
    instead of the graph partition ordering.

-   â€™pfeasâ€™ overrides the MSK_DPAR_INTPNT_CO_TOL_PFEAS parameter in
    MOSEK.

# Known issues

MOSEK can sometimes terminate with â€œSTATUS UNKNOWNâ€ despite seemingly
achieving reasonable accuracy in its terminal output. This can usually
be fixed by lowering the primal feasibility tolerance, albeit at the
cost of a less accurate solution.

    opt = struct('pfeas',1e-3); % Reduce MOSEK pfeas tolerance
    [U,v] = solveChordalConv(c,At,lb,ub,opt);

The issue seems to occur at extremely large scales, i.e. with *n* on the
order of 1 million or more, or with highly ill-conditioned data. (Full
credit to Martin S. Andersen for discovering this fix.)

# Acknowledgements

This code is developed by Richard Y. Zhang (ryz@illinois.edu). The
author gratefully acknowledges Martin S. Andersen for discussions and
advice, and for early numerical experiments.
